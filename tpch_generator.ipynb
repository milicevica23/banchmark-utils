{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current folder: /home/aleks/git/my-projects/banchmark-utils/sf1\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import os\n",
    "from deltalake.writer import write_deltalake\n",
    "from pathlib import Path\n",
    "\n",
    "sf = [1]#[1,10,20] \n",
    "tables= [\n",
    "    \"customer\"\n",
    "   ,\"lineitem\"\n",
    "   , \"nation\"\n",
    "   , \"orders\"\n",
    "   , \"part\"\n",
    "   , \"partsupp\"\n",
    "   , \"region\"\n",
    "   , \"supplier\" \n",
    "]\n",
    "\n",
    "base_path = Path(os.getcwd()) \n",
    "\n",
    "format = \"CSV\"\n",
    "\n",
    "con = duckdb.connect(':memory:')\n",
    "con.sql(\n",
    "    \"\"\"\n",
    "    INSTALL tpch;\n",
    "    LOAD tpch;\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "for sf_scale in sf:\n",
    "    current_folder_path = base_path / (\"sf\" + str(sf_scale)) \n",
    "    print(\"current folder: \" + str(current_folder_path))\n",
    "    con.sql(\n",
    "        f\"CALL dbgen(sf={sf_scale});\"\n",
    "    )\n",
    "    if not current_folder_path.exists():\n",
    "        os.mkdir(current_folder_path)\n",
    "    for table_name in tables: \n",
    "        if format == \"CSV\":\n",
    "            table_path = current_folder_path / \"csv\"\n",
    "            if not table_path.exists():\n",
    "                os.mkdir(table_path)\n",
    "            con.sql(f\"COPY {table_name} TO '{table_path / table_name }.csv' (DELIMITER '|', HEADER);\")\n",
    "        if format == \"DELTA\":\n",
    "            table_path_delta = current_folder_path / \"delta\" / table_name\n",
    "            df = con.sql(f\"SELECT * FROM {table_name}\").arrow()\n",
    "            write_deltalake(table_path_delta, df, mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\A108587977\\\\git\\\\tpch_data'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deltalake in ./.venv/lib/python3.11/site-packages (0.11.0)\n",
      "Requirement already satisfied: pyarrow<=12,>=8 in ./.venv/lib/python3.11/site-packages (from deltalake) (12.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in ./.venv/lib/python3.11/site-packages (from pyarrow<=12,>=8->deltalake) (1.26.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install deltalake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A108587977\\git\\tpch_data/sf1/customer.csv\n",
      "C:\\Users\\A108587977\\git\\tpch_data/sf1/lineitem.csv\n",
      "C:\\Users\\A108587977\\git\\tpch_data/sf1/nation.csv\n",
      "C:\\Users\\A108587977\\git\\tpch_data/sf1/orders.csv\n",
      "C:\\Users\\A108587977\\git\\tpch_data/sf1/part.csv\n",
      "C:\\Users\\A108587977\\git\\tpch_data/sf1/partsupp.csv\n",
      "C:\\Users\\A108587977\\git\\tpch_data/sf1/region.csv\n",
      "C:\\Users\\A108587977\\git\\tpch_data/sf1/supplier.csv\n"
     ]
    }
   ],
   "source": [
    "import polars as pl \n",
    "import pandas as pd\n",
    "sf = [1]#[1,10,20] \n",
    "tables= [\n",
    "    \"customer\"\n",
    "   ,\"lineitem\"\n",
    "   , \"nation\"\n",
    "   , \"orders\"\n",
    "   , \"part\"\n",
    "   , \"partsupp\"\n",
    "   , \"region\"\n",
    "   , \"supplier\" \n",
    "]\n",
    "\n",
    "base_path = os.getcwd() \n",
    "con_str = f\"mysql+pymysql://admin:C0lumnStore!@localhost:3307/test?charset=utf8mb4\"\n",
    "\n",
    "\n",
    "for table_name in tables:\n",
    "    table_path = base_path + \"/sf1/\" + table_name + \".csv\" \n",
    "    df = pl.read_csv(table_path,separator=\"|\")\n",
    "    print(table_path)\n",
    "    df.write_database(table_name,con_str)\n",
    "\n",
    "# for table_name in tables:\n",
    "#     table_path = base_path + \"/sf1/\" + table_name + \".csv\" \n",
    "#     df = pl.read_csv(table_path,separator=\"|\")\n",
    "#     print(table_path)\n",
    "#     df.head(0).write_database(\"column_\" + table_name,con_str, if_exists='replace')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
